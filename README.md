The Cliff Walking project using SARSA and Q-Learning involves navigating an agent across a gridworld while avoiding a cliff. SARSA (on-policy) updates state-action values based on the current policy, considering the next action during learning, while Q-Learning (off-policy) updates values assuming the best possible action. The goal is to teach the agent to find the optimal path while minimizing steps falling into the cliff, emphasizing differences between on-policy and off-policy learning approaches.


![](cliff_walking.gif)
